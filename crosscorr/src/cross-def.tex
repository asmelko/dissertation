\section{Cross-correlation}\label{sec:cross}

First, we would like to review the mathematical definition of the cross-correlation (which is the basis for the definition-based implementation). Subsequently, we have selected and presented four of the most typical cross-correlation application types. Finally, we describe how the cross-correlation can be computed using Fourier transform.

% -----------------------------------------------------------------------------
\subsection{Definition}\label{sec:cross_corr_def}
% -----------------------------------------------------------------------------

Cross-correlation, also known as sliding dot product or sliding inner product, is a function describing the similarity of two series or two functions based on their relative displacement
% \citep{site:wiki_cross_corr}.
Cross-correlation of functions $f,g: \mathbb{C} \rightarrow \mathbb{R}$, denoted as \(f \star g\), is defined by the following formula:
\[
	(f \star g)(\tau) = \int_{-\infty}^{\infty} \overline{f(t)}g(t + \tau) \,dt,
\] 

where \(\overline{f(t)}\) denotes the complex conjugate of \(f(t)\) and \(\tau\) is the displacement of the two functions \(f\) and \(g\). In simpler words, the value \((f \star g)(\tau)\) tells us how similar the function \(f\) is to \(g\) when \(g\) is shifted by \(\tau\), with a higher value representing higher similarity.

For two discrete functions, as will be used in our case, cross-correlation of functions \( f, g: \mathbb{Z} \rightarrow \mathbb{R} \) is defined by the following formula:

\[
(f \star g)[m] = \sum_{i=-\infty}^{\infty} \overline{f[i]}g[i + m],
\] 


This definition of cross-correlation can be extended for use in two dimensions, as is required, for example, in image processing.
For two discrete functions \( f, g : \mathbb{Z}^2 \rightarrow \mathbb{R} \), cross-correlation is defined as:

\[
(f \star g)[m,n] = \sum_{i=-\infty}^{\infty} \sum_{j=-\infty}^{\infty} \overline{f[i,j]}g[i + m,j + n],
\]

Even though cross-correlation is defined on the whole $\mathbb{Z}$ for one dimension and $\mathbb{Z}^2$ for two dimensions, most use cases of cross-correlation work only on finite inputs, such as image processing working on finite images. The only values we are interested in are those where the two images overlap, which restricts the computation to $(w_1 + w_2 - 1) \cdot (h_1 + h_2 - 1)$ resulting values, where $w_i$ denotes the width and $h_i$ denotes the height of the image $i$.

This limits the part of the output we are interested in and leads us to the time complexity of the \textit{na\"{i}ve} definition-based algorithm. For each of the $(w_1 + w_2 - 1) \cdot (h_1 + h_2 - 1)$ output values, we need to multiply the overlapping pixel values and sum up all the multiplication results. There will be at most $min(w_1, w_2) \cdot min(h_1, h_2)$ overlapping pixels. For simplicity, let us work with two images of the same size $w \cdot h$. Then the time complexity of the definition-based algorithm is $(2w-1) \cdot (2h - 1) \cdot \mathcal{O}(w \cdot h)$, which gives us asymptotic complexity of $\mathcal{O}(w^2 \cdot h^2)$.


% -----------------------------------------------------------------------------
\subsection{Forms of cross-correlation}\label{sec:cross_corr_forms}
% -----------------------------------------------------------------------------

In cross-correlation applications, several forms of computation can be found. Each enables different types of optimizations, such as data caching and data reuse, batching, or precomputing. These forms differ in the number of inputs and in the way cross-correlation is computed between the inputs. The four basic forms are depicted in Figure~\ref{fig:cross_corr_forms}:

\begin{enumerate}
	\item one left input with one right input, in the rest of the thesis referred to as \textit{one-to-one} and depicted in Figure \ref{fig:cross_corr_one_to_one};
	\item one left input with many right inputs, referred to as \textit{one-to-many} and depicted in Figure \ref{fig:cross_corr_one_to_many};
	\item $n$ left inputs, \textbf{each one} cross-correlated with $m$ \textbf{different} right inputs (multiple instances of \textit{one-to-many}), referred to as \textit{n-to-mn} and depicted in Figure \ref{fig:cross_corr_n_to_mn};
	\item $n$ left inputs, \textbf{all} cross-correlated with \textbf{all} $m$ right inputs (full bipartite graph), referred to as \textit{n-to-m} and depicted in Figure \ref{fig:cross_corr_n_to_m}.
\end{enumerate} 

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.4\textwidth}
		\centering
		\def\svgwidth{0.5\textwidth}
		\input{crosscorr/src/img/overlap-OneToOne.pdf_tex}
		\caption{one-to-one}
		\label{fig:cross_corr_one_to_one}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.4\textwidth}
		\centering
		\def\svgwidth{0.5\textwidth}
		\input{crosscorr/src/img/overlap-OneToMany.pdf_tex}
		\caption{one-to-many}
		\label{fig:cross_corr_one_to_many}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.4\textwidth}
		\centering
		\def\svgwidth{0.7\textwidth}
		\input{crosscorr/src/img/overlap-NtoMN.pdf_tex}
		\caption{n-to-mn}
		\label{fig:cross_corr_n_to_mn}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.4\textwidth}
		\centering
		\def\svgwidth{0.7\textwidth}
		\input{crosscorr/src/img/overlap-NToM.pdf_tex}
		\caption{n-to-m}
		\label{fig:cross_corr_n_to_m}
	\end{subfigure}
	
	\caption{Basic forms of cross-correlation}
	\label{fig:cross_corr_forms}
\end{figure}

The \textit{one-to-many} form is typical for applications where one sample (a~query) is located in a database or a time series of signal samples (e.g., in a~video sequence). Similarly, \textit{n-to-m} is merely an extension of this scenario where multiple queries are located in a database simultaneously \cite{Clark2011}. Perhaps the most unusual pattern is \textit{n-to-mn}. It has been inspired by the motivational application described in Section~\ref{sec:intro-motivation}. It is also an extension of \textit{one-to-many}, where both the query and the database samples are divided into corresponding sub-samples (e.g., areas with corresponding coordinates both in the query and database signals \cite{Kapinchev2015,zhang2015}). We have observed even more complex forms in the applications; however, they did not present any more opportunities for parallel processing or caching optimizations.

While each pair of input matrices can always be computed independently, the \textit{one-to-many}, \textit{n-to-mn} and \textit{n-to-m} types allow for the reuse of the left input matrix data for computation with multiple right input matrices. Additionally, the \textit{n-to-m} makes it possible to reuse data from the right matrix for computation with multiple left input matrices. 

For the same size of input data (i.e., $x$ left input matrices and $y$ right input matrices) the \textit{n-to-m} requires the computation of $x \cdot y$ pairs of matrices, compared to the \textit{n-to-mn} type which results in only $y$ pairs. The increased level of parallelism and increased arithmetic intensity allow for additional optimizations of the \textit{n-to-m} computation type compared to the \textit{n-to-mn} type. The \textit{one-to-one} and \textit{one-to-many} types are described separately, as compared to the general \textit{n-to-mn} or \textit{n-to-m} implementation, their implementations can more aggressively cache and reuse the left input matrix. 

Implementations of the two simpler types \textit{one-to-one} and \textit{one-to-many} can be extended to \textit{n-to-m} or \textit{n-to-mn} by running the simpler type of cross-correlation multiple times, possibly in parallel. Inversely, any implementation of either \textit{n-to-m} or \textit{n-to-mn} can be used to implement the two simpler types (with $n=1$). Another type that we could consider is the computation of a large number of independent pairs, which can be implemented by \textit{n-to-mn} (with $m=1$). A~large number of correlated pairs is a type not discussed further as it does not provide any additional opportunity for optimization compared to running the \textit{one-to-one} several times in parallel.



% -----------------------------------------------------------------------------
\subsection{Computation using Fourier transform}\label{sec:cross_corr_fft}
% -----------------------------------------------------------------------------

There is an alternate algorithm for computing cross-correlation based on the discrete Fourier transform (DFT). The asymptotic complexity of this algorithm (in two dimensions) is $\mathcal{O}(w \cdot h \cdot \log_2(w \cdot h))$, where $w$ is the width of each series and $h$ the height of each series. This improves on the asymptotic complexity $\mathcal{O}(w^2 \cdot h^2)$ of the definition-based algorithm described in the previous section, but the actual complexity constants are higher (thus, the FT-based implementation is better only for inputs larger than a certain threshold).

The Discrete Fourier transform can only be used to compute a special type of cross-correlation, the so-called \textit{circular} cross-correlation.
For a finite series $N \in \mathbb{N} \{x\}_n = x_0, x_1, ..., x_{N-1}, \{y_n\} = y_0, y_1, ..., y_{N-1}$, circular cross-correlation is defined as:

\[
(x \star_N y)_m = \sum_{i=0}^{N-1} \overline{x_m} y_{(m + i) \bmod N},
\]

where $\overline{x_m}$ denotes the complex conjugate of $x_m$.


Based on the Cross-Correlation Theorem~\cite{bracewell1966fourier}, the circular cross-correlation $(x \star_N y)_m$ can be computed using discrete Fourier transform (DFT) according to the following formula:

\[
(x \star_N y)_m = \mathbb{F}^{-1}(\overline{\mathbb{F}(x)}*\mathbb{F}(y))
\]

where $\mathbb{F}(x)$ and $\mathbb{F}(y)$ denote DFT of series $x$ and $y$ respectively, $\overline{\mathbb{F}(x)}$ denotes the complex conjugate of the DFT, $*$ denotes element-wise multiplication of two series and $\mathbb{F}^{-1}$ denotes inverse DFT.

To compute the non-circular (linear) cross-correlation of non-periodic series of size \textit{N}, we pad both series with \textit{N} zeros to the size \textit{2N}, as indicated in Figure \ref{fig:circular_cross_corr}. The results of circular cross-correlation are then the results of linear cross-correlation, only circularly shifted by $N-1$ places to the left with one additional 0 value at index $N$.

\begin{figure}[h]
	\centering
	\def\svgwidth{0.8\textwidth}
	\fontsize{9}{12}\selectfont
	\input{crosscorr/src/img/circular_cross_corr.drawio.pdf_tex}
	\caption{Comparison of linear and circular cross-correlation}
	\label{fig:circular_cross_corr}
\end{figure}


This process can be expanded into two dimensions, where the matrices are padded with \textit{N} rows and \textit{N} columns of zeros before being passed through 2D discrete Fourier transform. Here the circular shift of the results can be inverted by swapping the quadrants of the results while discarding row \textit{N} and column \textit{N}, which will be filled with zeros, as illustrated by Figure \ref{fig:quadrant_swap}. 

\begin{figure}[h]
	\centering
	\def\svgwidth{0.8\textwidth}
	\fontsize{9}{12}\selectfont
	\input{crosscorr/src/img/quadrant_swap.drawio.pdf_tex}
	\caption{The result quadrant swap}
	\label{fig:quadrant_swap}
\end{figure}


Based on this description, we can deduce the time complexity of the algorithm. For two matrices $a,b \in \mathbb{R}^{h \times w}$, the steps of the algorithm are:
\begin{enumerate}
	\item Padding $a_p, b_p \in \mathbb{R}^{2w \times 2h}$ of $a$ and $b$ with $w$ columns and $h$ rows of zeros in $\mathcal{O}(w \cdot h)$;
	\item The Discrete Fourier Transform (DFT) $A,B \in \mathbb{C}^{2w \times 2h}$ of $a_p$ and $b_p$ in $\mathcal{O}(w \cdot h \cdot \log_2(w \cdot h))$;
	\item Element-wise multiplication, also known as the Hadamard product, $C \in \mathbb{C}^{2w \times 2h}: C = \overline{A} \circ B$, where $\overline{A}$ the denotes complex conjugate of $A$, in $\mathcal{O}(w \cdot h)$;
	\item Inverse DFT $c \in \mathbb{R}^{2w \times 2h}$ of $C$ in $\mathcal{O}(w \cdot h \cdot \log_2(w \cdot h))$;
	\item Quadrant swap in $\mathcal{O}(w \cdot h)$
\end{enumerate}

In total, the steps described above give us an algorithm with asymptotic time complexity of $\mathcal{O}(w \cdot h \cdot \log_2(w \cdot h))$.

The FT-based algorithm will be used for comparison with the definition-based implementation. We have no ambition to optimize this algorithm further since the Fourier transform takes the most significant part and highly optimized libraries such as cuFFT\footnote{\url{https://docs.nvidia.com/cuda/cufft/}} already exist.
